<!DOCTYPE html>
<html lang="en">
<head>
    
    <meta charset="utf-8">
    <title>lexer.js - Documentation</title>
    
    
    <script src="scripts/prettify/prettify.js"></script>
    <script src="scripts/prettify/lang-css.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc.css">
    <script src="scripts/nav.js" defer></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>

<input type="checkbox" id="nav-trigger" class="nav-trigger" />
<label for="nav-trigger" class="navicon-button x">
  <div class="navicon"></div>
</label>

<label for="nav-trigger" class="overlay"></label>

<nav >
    
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Lexer.html">Lexer</a><ul class='methods'><li data-type='method'><a href="Lexer.html#tokenize">tokenize</a></li></ul></li><li><a href="LexicalError.html">LexicalError</a></li></ul>
</nav>

<div id="main">
    
    <h1 class="page-title">lexer.js</h1>
    

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * Lexical analyzer class.
 */


'use strict';

const LexicalError = require('./errors/lexical');
const Token = require('./token');
const {alphabetPatternList} = require('./terminals/alphabet');

/**
 * Lexical analyzer.
 *
 * Analyze each lexeme from the given text in according to language alphabet/terminals/grammar.
 */
class Lexer {
    /**
     * Lexer constructor.
     *
     * @constructor
     * @param {string} text - plain text as code source
     *
     * @return {Lexer} instance of Lexer analyzer
     */
    constructor ( text ) {
        this.text = text.trim();
        this.position = 0;
        this.tokenList = [];
    }

    /**
     * Tokenize source code.
     *
     * Analyze source text/code in according to language grammar and produce a structure of tokens.
     *
     * @return {Token[]} array of Token instances
     */
    tokenize () {
        const textLength = this.text.length;

        while ( this.position &lt; textLength ) {
            if ( /\S/.test(this.text[this.position]) ) {
                let match;

                const token = alphabetPatternList.find(item => {
                    match = this.text.slice(this.position).match(item.pattern);

                    return Boolean(match);
                });

                if ( !token ) {
                    throw new LexicalError(this.position);
                }

                this.tokenList.push(new Token(
                    this.position,
                    token.group,
                    token.type,
                    match[0]
                ));

                this.position += match[0].length;
            } else {
                ++this.position;
            }
        }

        return this.tokenList;
    }
}


module.exports = Lexer;
</code></pre>
        </article>
    </section>




    
    
</div>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.6.7</a> on Thu Aug 19 2021 13:17:13 GMT+0300 (Eastern European Summer Time) using the <a href="https://github.com/clenemt/docdash">docdash</a> theme.
</footer>

<script>prettyPrint();</script>
<script src="scripts/polyfill.js"></script>
<script src="scripts/linenumber.js"></script>



</body>
</html>
